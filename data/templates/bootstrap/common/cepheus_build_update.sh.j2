#!/bin/bash
#
# Author: Chris Jones <chris.jones@lambdastack.io>
# Copyright 2017, LambdaStack
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# NB: The initial build process: Chef Server and Chef Clients are installed and setup along with everything else.
# NB: The update process: Chef Server and Chef Client are NOT automatically updated but cookbooks and other supporting files are!

set -e

# Force a new clone
REPO_ROOT={{ cache.repo }}
REPO_ROOT_FILES={{ cache.base }}
TMP_REPO_ROOT_FILES=$REPO_ROOT_FILES

WORK_DIR={{ build.work_dir }}
DATE=$(date +%Y-%m-%d_%H%M%S)
VERSION={{ version }}

CLUSTER={{ data_center }}
CEPH_CHEF_BOOTSTRAP={{ bootstrap.name }}

# Change to whatever owner/group you like - NB: group was primary_user.group
OWNER={{ primary_user.name }}
GROUP={{ primary_user.name }}

KNIFE=/opt/opscode/embedded/bin/knife

# NB: Clear if exists
if [[ -d $WORK_DIR ]]; then
  rm -rf $WORK_DIR
fi

# Pulls down the github.com/cepheus-io/cepheus-staging repo to $WORK_DIR/cepheus-staging
# NOTE: It will prompt for your credentials by default
# Instead of tokens/keys - enforce temp cache of credentials - change it later if desired

# This is OK since only cloning/pulling. It only caches the credentials long enough to pull in all of the repos.
git config --global credential.helper cache
git config --global credential.helper 'cache --timeout=25'

# If opscode does not exist then Chef has not been installed yet and this is a fresh build.
{% if primary_user.backup.enable %}
if [[ -d "/opt/opscode/" ]]; then
    if [[ -d $REPO_ROOT ]]; then
        {% if primary_user.backup.remote.enable %}
        # Call the backup and rsync script
        source $REPO_ROOT/cepheus_backup_rsync.sh $DATE $VERSION
        {% else %}
        # Call the backup
        source $REPO_ROOT/cepheus_backup_no_rsync.sh $DATE $VERSION
        {% endif %}
    fi
fi
{%- endif %}

# IMPORTANT: NEVER push ONLY pull/clone
# Pull down (public) cepheus (cepheus-public-staging)
# If the repo exists it will processed first and then the commands if they exists.
{% for item in staging.process %}
# {{ item.comment }}
{%- if item.repo %}
git clone -b {{ item.branch }} {{ item.repo }} {{ item.output }}
{% endif %}
{%- if item.command %}
{{ item.command }}
{%- endif %}

{%- endfor %}

# Copy data over staging in order...
# echo "====> Layering data..."
# cp -rp $WORK_DIR/cepheus-private-staging/* $WORK_DIR/cepheus-public-staging/
# cp -rp $WORK_DIR/ceph-chef-private-staging/* $WORK_DIR/ceph-chef-public-staging/
#
# cp $WORK_DIR/cepheus-files-staging/cookbooks/*.tar.gz $WORK_DIR/cepheus-public-staging/cookbooks
#
# cd $WORK_DIR/cepheus-public-staging/cookbooks && ls -1 *.tar.gz | xargs -I% tar xvzf %
# cd $WORK_DIR/cepheus-public-staging/cookbooks && rm -f *.tar.gz
# sudo chown -R $OWNER:$GROUP $WORK_DIR/cepheus-public-staging
#
# cp -rp $WORK_DIR/ceph-chef-public-staging/* $WORK_DIR/cepheus-public-staging/cookbooks/ceph-chef/
# cp -rp $WORK_DIR/cepheus-data-staging/* $WORK_DIR/cepheus-public-staging/

# Create template files for staging before moving...
# echo "====> Creating files from templates for 'cepheus-public-staging'..."
# cd $WORK_DIR/cepheus-public-staging
# ./CEPH_UP -x -z $WORK_DIR/cepheus-public-staging

echo
echo "====> Clean staging process directories..."
# Clean up staging process directories if they exist
# NOTE: Important - Do this BEFORE moving data into directories on bootstrap since *all* is used!!

# NOTE: Come back to this later because attempting to run this section on new system fails badly!
# set +e
# # Only if Chef has been installed which means ansible is loaded and host files exist
# if [[ -d "/opt/opscode/" ]]; then
#     # Nodes may not exist during initial build so it's ok to fail...
#     ansible all -m shell -a "sudo rm -rf $REPO_ROOT"
#     ansible all -m shell -a "sudo rm -rf $REPO_ROOT_FILES"
# fi
# set -e

echo "====> Building update..."
# Build new {{ cache.repo }} environment and replace existing version

# Create dir even though it may already exist
sudo mkdir -p $REPO_ROOT
sudo chown -R $OWNER:$GROUP $REPO_ROOT

if [[ $(ls -A {{ cache.repo }}) ]]; then
    sudo rm -rf $REPO_ROOT/*
fi

# Force this to be original value
REPO_ROOT_FILES=$TMP_REPO_ROOT_FILES

echo "====> Copying data to $REPO_ROOT..."
ls $WORK_DIR/cepheus-public-staging
cp -rp $WORK_DIR/cepheus-public-staging/* $REPO_ROOT
sudo chown -R $OWNER:$GROUP $REPO_ROOT

####
# NB: This process may seem a little odd at first depending on the environment. For Vagrant the commands above 'cp'
# to the cepheus-staging because it pulls in the dependencies via the bootstrap_prereqs.sh. However, other environments
# may pull in from internal github or artifactory or something else. So, this makes sure it gets filled. May change later.
# Update {{ cache.base }}/ (supporting files - dependencies)
sudo mkdir -p $REPO_ROOT_FILES
sudo chown -R $OWNER:$GROUP $REPO_ROOT_FILES
#

if [[ $(ls -A $REPO_ROOT_FILES) ]]; then
    sudo rm -rf $REPO_ROOT_FILES/*
fi
#
echo "====> Copying files to $REPO_ROOT_FILES..."
cp -r $WORK_DIR/cepheus-files-staging/* $REPO_ROOT_FILES
sudo chown -R $OWNER:$GROUP $REPO_ROOT_FILES
#
####

# Build...
echo "====> Building from templates..."

# Build from template
{%- for item in build_update_files %}
{% if item.sudo %}
SUDO=sudo
{% else %}
SUDO=
{%- endif %}
echo {{ item.echo }}
$SUDO $REPO_ROOT/data/templates/template_engine -d $REPO_ROOT/data/$BUILD_LOCATION/$BUILD_DATA_CENTER/build.yaml -i {{ item.input }} -o {{ item.output }}
# NB: Pass through template_engine twice
$SUDO $REPO_ROOT/data/templates/template_engine -d $REPO_ROOT/data/$BUILD_LOCATION/$BUILD_DATA_CENTER/build.yaml -i {{ item.output }} -o {{ item.output }}
{%- endfor %}

# Sync $HOME/cepheus with {{ cache.repo }}
echo "====> Syncing $REPO_ROOT and $HOME/cepheus..."
sudo rm -rf $HOME/cepheus/*
cp -rp $REPO_ROOT/* $HOME/cepheus

# Make sure it's {{ primary_user.name }} as owner:group
sudo chown -R $OWNER:$GROUP $HOME/cepheus

# Update chef info
echo "====> Setting Chef Environment..."
cd $HOME/cepheus/environments && $KNIFE environment from file {{ environment }}.json
echo "====> Setting Chef Roles..."
cd $HOME/cepheus/roles && $KNIFE role from file *.json
echo "====> Uploading Chef cookbooks..."
$KNIFE cookbook upload -a

# Bootstrap node will never change or should never change...
# Add Chef tags
# NOTE: run_list *set* replaces any run_list that may have already been there before
# echo "====> Setting Chef Bootstrap Run-list..."
# knife node run_list set {{ bootstrap.name }} 'role[ceph-bootstrap]'
# echo "====> Setting Chef Bootstrap Environment..."
# knife node environment set {{ bootstrap.name }} {{ environment }}
# echo "====> Setting Chef Bootstrap Tag..."
# knife tag create {{ bootstrap.name }} 'ceph-bootstrap'

echo "====> Building Chef ENV..."
sudo chef-client -o 'recipe[cepheus::build-env]'

# Update Chef tags
echo "====> Calling Chef tags..."
{{ cache.repo }}/bootstrap/common/chef_tags_delete.sh
{{ cache.repo }}/bootstrap/common/chef_tags_create.sh

# Make sure the production environment is always set
echo "====> Calling Chef environments..."
{{ cache.repo }}/bootstrap/common/chef_environment_nodes.sh {{ environment }}

# Update run_lists
echo "====> Calling Chef run-lists..."
{{ cache.repo }}/bootstrap/common/chef_runlists_update.sh

# Update bootstrap node
##################
# Tmp comment out for testing...
echo "====> Running Chef-Client..."
sudo chef-client

logger -t CepheusBackup "Cepheus Chef Server updated to latest packages - $VERSION-$DATE"

# Make sure tmp files are present for cookbooks
# Hack around gem issue - one of Chef's bad things...
# NB: Fix in future - Should only run these ansible runs *IF* nodes exists but for now it's ok if they fail on intial run...
set +e
# {% for item in ceph_chef.gems %}
# ansible all -m copy -a "src=$REPO_ROOT_FILES/gems/{{ item.name }}-{{ item.version }}.gem dest=/tmp/{{ item.name }}-{{ item.version }}.gem owner=$OWNER"
# {% endfor %}

# Backup ALL important configs, keys etc
# I have seen this sometimes hang - maybe due to doing a number of crush map gets which means it needs to be
# optimized to only get configs for each of the node groups since the configs are the same for all in that group and
# then maybe store the backup on the bootstrap as well as the primary node in the given group. Until then, it's OK to ctrl-c out of it.

# ansible {{ inventory.ceph.backup.primary.mon }},{{ inventory.ceph.backup.primary.osd }},{{ inventory.ceph.backup.primary.rgw }} -m shell -a "sudo /etc/ceph/scripts/ceph_backup_files.sh $VERSION $DATE"
set -e
##################

# Now you can run chef-client on the nodes

# Remove tmp working directory
rm -rf $WORK_DIR

echo "====> cepheus_build_update.sh Success!"
echo
