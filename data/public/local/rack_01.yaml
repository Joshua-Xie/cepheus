---

# Rack specific yaml file - TO BE USED ONLY as part of larger generated 'build.yaml'
# NB: Since this rack file is related to `local` `vagrant` then most of the fields below are really not needed.
# The bulk of the items below related to PXE Booting only.

rack_01:
    # NIC device names based on the hardware
    # Only here as a reference since they are actually defined in the environment.yaml
    # device1_1U: &device1_1U enp0s8
    # device2_1U: &device2_1U enp0s9
    # device1_2U: &device1_2U enp0s8
    # device2_2U: &device2_2U enp0s9

    # Netmask and CIDR of rack
    netmask: 255.255.255.0
    cidr: 24

    interfaces:
        public:
            # ToR IP address (gateway)
            gateway:
            mtu: 1500
            # IP prefix is put here so as to not have to have too much redundant info
            # NOTE: ip_prefix has trailing '.'
            ip_prefix: 10.0.100.
        cluster:
            # NOTE: Set gateway to empty so that ARP is not confused on the second interface since both gateways go to the same MAC address (the switch)
            gateway:
            mtu: 1500
            # IP prefix is put here so as to not have to have too much redundant info
            # NOTE: ip_prefix has trailing '.'
            ip_prefix: 10.121.2.

    nodes:
        # This node's primary role is Bootstrap. Because of that it will not be in the Cobbler system list so *NO* mac addresses needed!
        # It's mainly here for automation and completness.
        - name: ceph-boostrap
          ipmi:
              name: ceph-boostrap-mgmt
              ip: 10.123.85.130
          roles:
              - bootstrap
          # Profile is PXE related so bootstrap node is empty
          profile: ""
          public:
              device: *device1_1U
              ip: 20
              mac:
          cluster:
              device: *device2_1U
              ip: 20
              mac:

        - name: ceph-vm1
          ipmi:
              name: ceph-vm1-mgmt
              ip: 10.123.85.131
          roles:
              - mon
              - osd
              - rgw
              - admin
          # Profile is PXE related. If an OSD role is being used on PXE then set profile to `ceph_osd_node` instead of `ceph_non_osd_node`
          profile: ceph_osd_node
          public:
              device: *device1_1U
              ip: 21
              mac:
          cluster:
              device: *device2_1U
              ip: 21
              mac:

        - name: ceph-vm2
          ipmi:
              name: ceph-vm2-mgmt
              ip: 10.123.85.132
          roles:
              - mon
              - osd
              - rgw
              - admin
          # Profile is PXE related. If an OSD role is being used on PXE then set profile to `ceph_osd_node` instead of `ceph_non_osd_node`
          profile: ceph_osd_node
          public:
              device: *device1_1U
              ip: 22
              mac:
          cluster:
              device: *device2_1U
              ip: 22
              mac:

        - name: ceph-vm3
          ipmi:
              name: ceph-vm3-mgmt
              ip: 10.123.85.133
          roles:
              - mon
              - osd
              - rgw
              - admin
          # Profile is PXE related. If an OSD role is being used on PXE then set profile to `ceph_osd_node` instead of `ceph_non_osd_node`
          profile: ceph_osd_node
          public:
              device: *device1_1U
              ip: 23
              mac:
          cluster:
              device: *device2_1U
              ip: 23
              mac:
