#!/bin/bash
#
# Copyright 2017, LambdaStack
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# NB: This script is a ground up build of an entire Ceph cluster that also PXE boots every server in the cluster
# applies the given roles to each node based on the yaml data files.

# DO NOT RUN for an existing Ceph cluster! It will wipe everything out and start over with a fresh OS etc!

########## IMPORTANT ##########
# MUST create a github credential file *UNLESS* you are only using ONE set of github credentials. The process will
# source the credential file before doing the private git request and then set the previous credentials back after.
# For example: If you have a set of credentials for your own personal Github account where the 'public' portion of the
# project exists but you are also using an private Enterprise Github account that uses a different set of credentials
# for 'private' portions such as data or things specific to your organization then the credentials file will be your
# Enterprise Github credentials. The credentials file is a normal Github style credentials file but you can name it
# anything you like since it's only used here.
###############################

# This script builds the VirtualBox build VM required to build the bootstrap ISO. It must be ran from a desktop or
# laptop or anywhere that has full Internet access with or without a proxy.

# The boostrap ISO will be used to build the initial bootstrap node in the cluster. This is done via *moving* the ISO
# to an area in the Network where the ISO can be copied *OR* mounted by the initial bootstrap node. For example,
# the KVM interface will need access to the ISO so it can use it to build the boostrap node via the kickstart file on
# the ISO. For example, you may have a common drive share that your IPMI system can see. Put the ISO there and then
# login to the IPMI interface of the boostrap node and mount the ISO and start/restart the node. The normal process
# take over and the custom kickstart will automatically build the boostrap node.

# The ISO build process will build a final ISO that includes the following:
# 1. Updated packages
# 2. Modified *repodata* that has been re-indexed to support an additional packages
# 3. Modified *isolinux/isolinux.cfg that has been updated to automatically start the OS build using
#    a new kickstart file that is found in the cepheus/files/default/cepheus_bootstrap_rhel.ks.
# 4. New directories called /postinstall/{ceph-files,ceph-host}. These contain the pre-req colleced files/packages
#    downloaded via 'bootstrap_prereqs.sh'.

# The custom kickstart will build the OS, partition the drive and do RAID1 on second drive, setup NICs on bootstrap
# and copy over 'postinstall' directories to the /tmp directory on bootstrap. The 'postinstall' directory contains the
# Chef server and all required prereq packages/files. It also contains the Red Hat Satellite key for the repos if using
# Red Hat Satellite servers.

# Vagrant creates the build VM and in this script and you can access the VM with BUILD_NEW_ENV and *NOT* CEPH_UP!

# Once on the newly built bootstrap node is running you can run (sudo) the 'build_bootstrap_node.sh'. This will create
# the structure for the Chef Server, move over the ISO used to build the rest of the nodes, build the Chef
# server and prep it with all of the cookbooks and make sure Cobbler is ready to go. Once you're satisfied
# with the bootstrap node then start the PXE booting of the cluster. Also, there are two types of kickstart files,
# OSD and NON-OSD. The difference is mainly the drive configuration. Each of the kickstarts also have the Red Hat
# Satellite key built in for the packages if using Red Hat Satellite server.

# Red Hat Only
# Note: If needed and Satellite server is not available then the bootstrap kickstart can be modified to copy over
# the packages to the Cobbler repo_mirror directory (/var/www/pxe_boot/repo_mirror) and then run createrepo to
# generate the indexes and setup the *.repo file in /etc/yum.repos.d/. The node kickstarts would need to be
# modified too to pull repo from the bootstrap node instead of the Satellite server via the Capsule server. If this
# process is used instead of Satellite then you must keep the packages updated via mounted ISO process.

set -e

# CAN ONLY be ran from the /cepheus/bootstrap/vms/vagrant directory!

# NB: Example:
# ./BUILD_NEW_ENV -d dc1 -e production -c

clear

while getopts bc:d:e:g:p:v opt; do
  case $opt in
    b)
        # This just builds the 'Build Server' and does not complete the process of building the custom ISO.
        BUILD_VMS_ONLY=1
        ;;
    d)
        # (required) Data center label. This allows you the flexability to have different data centers which of course
        # will have different data. This value is used to complete the PATH of where to find the yaml data files.
        # For example, `nyc1` or `wdc1`. This value is on of the same values found in your `build.yaml` file.
        dc=$OPTARG
        ;;
    e)
        # (required) Environment that must match the Chef environment file. For example, `vagrant` or `production`.
        # This value is one of the values found in your `build.yaml` file. The final file will be <whatever>.json
        # that will be located in the 'environment' directory which is used by Chef to build and manage your cluster.
        env=$OPTARG
        ;;
    g)
        # (optional) private_git. If this value is not set then it will be assumed that all data is found in the
        # public github repo.
        private_git=$OPTARG
        ;;
    c)
        # (optional) Sample of a credential_file is in `/data/sample_git_credentials_file`. This would only be used
        # in cases where your GIT credentials for the 'private_git' (-g above) is different than your public github repo.
        credential_file=$OPTARG
        ;;
    p)
        # (optional) If your environment requires a proxy then it must be set using -p <proxy url>
        BOOTSTRAP_HTTP_PROXY=$OPTARG
        BOOTSTRAP_HTTPS_PROXY=$OPTARG
        ;;
    v)
        # (optional) Verbose of `bash` commands and not Chef output
        set -x
        ;;
  esac
done

# Just setting it to 0 here...
export CEPH_DEV_MODE=${CEPH_DEV_MODE:-0}

export BOOTSTRAP_HTTP_PROXY=${BOOTSTRAP_HTTP_PROXY:-}
export BOOTSTRAP_HTTPS_PROXY=${BOOTSTRAP_HTTPS_PROXY:-}
export CHEF_CEPHEUS_DEBUG=${CHEF_CEPHEUS_DEBUG:-0}
export BUILD_VMS_ONLY=${BUILD_VMS_ONLY:-0}

# NOTE: Check your private data documentation for these values before running this!

if [[ -z $env ]]; then
  echo "IMPORTANT - environment *MUST* be passed in (i.e., production, Test-Laptop, vagrant or whatever you call it but it must match the directory structure in /bootstrap/data/environment/???)"
  exit 1
fi

if [[ -z $dc ]]; then
  echo "IMPORTANT - (Data center) environment *MUST* be passed in (i.e., dc1, dc2, whatever you call it but it must match the directory structure in /bootstrap/data/environment/$env/???)"
  exit 1
fi

echo
echo "             __     "
echo "             \ \    "
echo "              > \   "
echo "             / ^ \  "
echo "            /_/ \_\ "
echo
echo "Cepheus Build Process..."
echo "-----------------------------------------------------------------------------"
echo "Building a Cepheus ISO to be used for the $env environment in data center $dc"
echo

# Build dns.txt and hosts before doing anything else
# NOTE IMPORTANT - These two scripts are *NOT* included in the public repo because they are specific to your *specific* environment.
# You can comment them out or add two scripts that build your dns and hosts files.
# If these two do not exist in your environment then the script will fail here!

# NOTE: REPO_ROOT will change to the cache directory later in this process
export REPO_ROOT=$(git rev-parse --show-toplevel)

# Using environment vars from CEPH_UP :)

# Force banner not to show
export DONT_SHOW_BANNER=1
# Force no download of ISO which means it has already been download - see below
export COBBLER_DOWNLOAD_ISO=0

source $REPO_ROOT/bootstrap/vms/vagrant/vagrant_base.sh

do_on_node() {
  echo
  echo "Issuing command: vagrant ssh $1 -c ${2}"
  echo "----------------------------------------------------------------------------------------"
  NODE=$1
  shift
  COMMAND="${*}"
  vagrant ssh $NODE -c "$COMMAND"
}

#### Modify section - begin ####
CHEF_CEPHEUS_ENV=$dc
BUILD_ENV=$env/$CHEF_CEPHEUS_ENV
# The name of the build server. Change it in build_server_config *AND* here!
vm=cepheus-build-server
CEPH_CHEF_FILES=ceph-files
CEPH_CHEF_REPO=ceph-host
ISOVOLUMEID="RHEL-7.2 Server.x86_64"
PACKAGER=LambdaStack
COMPS_FILE=comps.xml
ks=cepheus_bootstrap_rhel.ks.j2

# IMPORTANT!! These vars *MUST* be set to either the http location for download OR the file location on your local
# file system. Everything but RHEL can be downloaded via http. RHEL must be downloaded *BEFORE* starting this process.
# The location of where you put RHEL should be set here if RHEL. The default is the Downloads area on a mac.
export COBBLER_REMOTE_URL_ISO="$HOME/Downloads/rhel-server-7.2-x86_64-dvd.iso"
export COBBLER_BOOTSTRAP_ISO="rhel-server-7.2-x86_64.iso"

# NOTE: IMPORTANT - The private repo (if one) *MUST* be in the same structure as the public github version.
# The private repo will override the public version so *ONLY* put files in the private repo that you don't want
# to be public AND that you want to take priority!
export GITHUB_PUBLIC_LAYER_REPO=${GITHUB_PUBLIC_LAYER_REPO:-"cepheus"}
export GITHUB_PRIVATE_LAYER_REPO=${GITHUB_PRIVATE_LAYER_REPO:-"cepheus-private"}
export GITHUB_PUBLIC_REPO=${GITHUB_PUBLIC_REPO:-"https://github.com/cepheus-io/$GITHUB_PUBLIC_LAYER_REPO"}

# NB: Optional for Private Git. If not passed in then the public github account will be used (should use private repo)
if [[ ! -z $private_git ]]; then
    export GITHUB_PRIVATE_REPO=${GITHUB_PRIVATE_REPO:-"https://$private_git/$GITHUB_PRIVATE_LAYER_REPO"}
fi
#### Modify section - end ####

rm -rf $BOOTSTRAP_CACHE_DIR/build/iso/in
rm -rf $BOOTSTRAP_CACHE_DIR/build/iso/out
mkdir -p $BOOTSTRAP_CACHE_DIR/build/iso/{in,out}

# Configure and test any proxies configured.
if [[ ! -z $BOOTSTRAP_HTTP_PROXY ]] || [[ ! -z $BOOTSTRAP_HTTPS_PROXY ]] ; then
  echo "===> Testing configured proxies..."
  source $REPO_ROOT/bootstrap/common/bootstrap_proxy_setup.sh
fi

export BOOTSTRAP_TYPE=${BOOTSTRAP_TYPE:-"vagrant"}

# Perform preflight checks to validate environment sanity as much as possible.
echo "===> Performing preflight environment validation..."
source $REPO_ROOT/bootstrap/common/bootstrap_validate_env.sh

echo "===> Checking VirtualBox and Vagrant..."
source $REPO_ROOT/bootstrap/vms/vagrant/vagrant_test.sh

# Do prerequisite work prior to starting build, downloading files and
# creating local directories.
echo "===> Downloading necessary files to local cache..."
source $REPO_ROOT/bootstrap/common/bootstrap_prereqs.sh

# Just remove pxe_boot iso to make sure it's clean
rm -f $BOOTSTRAP_CACHE_DIR/pxe_boot/isos/*

# Copy over RHEL
echo "===> Copying ISO to cache..."
if [[ ! -f $BOOTSTRAP_CACHE_DIR/build/iso/in/$COBBLER_BOOTSTRAP_ISO ]]; then
  cp $COBBLER_REMOTE_URL_ISO $BOOTSTRAP_CACHE_DIR/build/iso/in/$COBBLER_BOOTSTRAP_ISO
fi

# Get the cepheus github repo and any private github (note: change this to fit your needs).
# Put these in the cache directory where the shared folders will be mapped.
# Force a clean git clone
set +e
rm -rf $BOOTSTRAP_CACHE_DIR/build/github/public
rm -rf $BOOTSTRAP_CACHE_DIR/build/github/private
rm -rf $BOOTSTRAP_CACHE_DIR/build/github/combined
mkdir -p $BOOTSTRAP_CACHE_DIR/build/github/{public,private,combined}
set -e

# No need to reset the GITHUB metadata here
git clone $GITHUB_PUBLIC_REPO $BOOTSTRAP_CACHE_DIR/build/github/public/$GITHUB_PUBLIC_LAYER_REPO

echo "===> Git (Internal): $GITHUB_PRIVATE_REPO"

# May be there so ignore fail if not there.
set +e
if [[ ! -z $private_git ]]; then
  GITHUB_EMAIL=$(git config --global user.email)
  GITHUB_NAME=$(git config --global user.name)
  GITHUB_HTTP_PROXY=$(git config --global http.proxy)
  GITHUB_HTTPS_PROXY=$(git config --global https.proxy)

  if [[ ! -z $credential_file ]]; then
    source $credential_file
  fi

  git clone $GITHUB_PRIVATE_REPO $BOOTSTRAP_CACHE_DIR/build/github/private/$GITHUB_PRIVATE_LAYER_REPO

  if [[ ! -z $credential_file ]]; then
    git config --global user.name $GITHUB_NAME
    git config --global user.email $GITHUB_EMAIL
    git config --global http.proxy $GITHUB_HTTP_PROXY
    git config --global htpps.proxy $GITHUB_HTTPS_PROXY
  fi
fi
set -e

# Overlay private over public to form combined
cp -r $BOOTSTRAP_CACHE_DIR/build/github/public/$GITHUB_PUBLIC_LAYER_REPO/ $BOOTSTRAP_CACHE_DIR/build/github/combined/cepheus/
cp -r $BOOTSTRAP_CACHE_DIR/build/github/private/$GITHUB_PRIVATE_LAYER_REPO/ $BOOTSTRAP_CACHE_DIR/build/github/combined/cepheus/

# By changing the repo_root it forces the use of github and any private git
echo '===> Setting REPO_ROOT to cache directory...'
export REPO_ROOT=$BOOTSTRAP_CACHE_DIR

# NOTE: Run these from their respective directories *before* running this script. Leaving the comments here for now...
#echo "Building DNS and hosts files..."
#$BOOTSTRAP_CACHE_DIR/build/github/combined/$GITHUB_PUBLIC_LAYER_REPO/bootstrap/data/environment/$env/scripts/build_dns_file.sh $dc
#$BOOTSTRAP_CACHE_DIR/build/github/combined/$GITHUB_PUBLIC_LAYER_REPO/bootstrap/data/environment/$env/scripts/build_hosts_file.sh $dc

# NOTE: (IMPORTANT) - Overlay the private repo on the public repo in the cache path

# An alternative to the above git clone is to have the clone somewhere on your system and then sym link to it instead :)

# IMPORTANT!!!!!
# Copy over the Vagrantfile_build_env to Vagrantfile
# There are two Vagrantfile* files. One for building the build environment (Vagrant_build_env) and one for
# building the CEPHEUS cluster (Vagrantfile_cepheus) for testing.
cp -p $REPO_ROOT/bootstrap/vms/vagrant/Vagrantfile_build_env $REPO_ROOT/bootstrap/vms/vagrant/Vagrantfile

# Clean up old build vm
# Since the earlier cp command copied the Vagrantfile_build_env to Vagrantfile then only that VM will be destroyed
vagrant destroy -f

# Create VM.
# Since the earlier cp command copied the Vagrantfile_build_env to Vagrantfile then only that VM will be built
vagrant up

echo
echo "===> Vagrant build complete..."
echo

if [[ $BUILD_VMS_ONLY -eq 0 ]]; then
  echo "===> Copying ISO to /tmp..."
  echo
  # Move the ISO because we rsync later
  do_on_node $vm "mv /ceph-files/build/iso/in/rhel*.iso /tmp"

  echo "===> Creating directories and mounting base ISO..."
  echo
  do_on_node $vm "mkdir -p /tmp/build/{iso,mnt,packages,keys}"
  do_on_node $vm "sudo mount -o loop /tmp/$COBBLER_BOOTSTRAP_ISO /tmp/build/mnt"

  echo "===> Moving ISO data to /tmp/build/iso..."
  echo
  do_on_node $vm "rsync -av /tmp/build/mnt/ /tmp/build/iso/"
  do_on_node $vm "sudo mkdir -p /tmp/build/iso/postinstall/ceph-files/keys"
  do_on_node $vm "sudo mkdir -p /tmp/build/iso/ks"
  do_on_node $vm "sudo chown vagrant:vagrant /tmp/build/iso/postinstall"
  do_on_node $vm "sudo chown vagrant:vagrant /tmp/build/iso/ks"

  # Currently not modifying the packages so no need to update *comps*.xml and do createrepo
  # If packages were updated then several other steps would need to be performed
  do_on_node $vm "sudo umount /tmp/build/mnt"
  do_on_node $vm "sudo find /tmp/build/iso -name TRANS.TBL -exec rm -f {} \;"

  # Copy over ceph-files and to postinstall
  echo "===> Copying $CEPH_CHEF_FILES to ISO..."
  echo
  # No ceph-host in this part of build cycle. The ceph-host will be made on actual bootstrap node during
  # kickstart post install cycle.
  do_on_node $vm "sudo rsync -av /ceph-files/ /tmp/build/iso/postinstall/ceph-files/"
  do_on_node $vm "sudo rsync -av /ceph-host/ /tmp/build/iso/postinstall/ceph-host/"
  do_on_node $vm "sudo find /tmp/build/iso/postinstall/ceph-files -name *_downloaded -exec rm -f {} \;"
  do_on_node $vm "sudo pip install --upgrade pip"
  do_on_node $vm "sudo pip install --index-url=http://pypi.python.org/simple/ --trusted-host pypi.python.org pyyaml"

  # Build the initial bootstrap_chef.sh script in the data center specific folder
  do_on_node $vm "sudo /ceph-host/data/templates/template_engine -d /ceph-host/bootstrap/data/environment/$BUILD_ENV/base-seed.yaml -i /ceph-host/bootstrap/data/environment/$env/bootstrap_chef.sh.j2 -o /tmp/build/iso/postinstall/ceph-host/bootstrap/data/environment/$env/$dc/bootstrap_chef.sh"
  do_on_node $vm "sudo chmod +x /tmp/build/iso/postinstall/ceph-host/bootstrap/data/environment/$env/$dc/bootstrap_chef.sh"

  # Build base.sh script
  do_on_node $vm "sudo /ceph-host/data/templates/template_engine -d /ceph-host/bootstrap/data/environment/$BUILD_ENV/base-seed.yaml -i /ceph-host/bootstrap/data/environment/$env/base.sh.j2 -o /tmp/build/iso/postinstall/ceph-host/bootstrap/data/environment/$env/scripts/base.sh"
  do_on_node $vm "sudo chmod +x /tmp/build/iso/postinstall/ceph-host/bootstrap/data/environment/$env/scripts/base.sh"

  # Build Data - isolinux.cfg
  do_on_node $vm "sudo /ceph-host/data/templates/template_engine -d /ceph-host/bootstrap/data/environment/$BUILD_ENV/base-seed.yaml -i /ceph-host/data/templates/isolinux.cfg.j2 -o /tmp/build/iso/isolinux/isolinux.cfg"
  do_on_node $vm "sudo /ceph-host/data/templates/template_engine -d /ceph-host/bootstrap/data/environment/$BUILD_ENV/base-seed.yaml -i /ceph-host/data/templates/cepheus_bootstrap_rhel.ks.j2 -o /tmp/build/iso/ks/cepheus_bootstrap_rhel.ks"

  # NOTE: Yes, it's true...the output is another .j2 becase it does multiple passes.
  do_on_node $vm "sudo /ceph-host/data/templates/template_engine -d /ceph-host/bootstrap/data/environment/$BUILD_ENV/base-seed.yaml -i /ceph-host/data/templates/$env.json.j2 -o /tmp/build/iso/postinstall/ceph-host/environments/$env.json.j2"

  # Overrides dummy operations.pub in files/default
  do_on_node $vm "sudo /ceph-host/data/templates/template_engine -d /ceph-host/bootstrap/data/environment/$BUILD_ENV/base-seed.yaml -i /ceph-host/data/templates/operations.pub.j2 -o /tmp/build/iso/postinstall/ceph-host/cookbooks/cepheus/files/default/operations.pub"

  # Build kickstart template to be used by Chef
  do_on_node $vm "sudo /ceph-host/data/templates/template_engine -d /ceph-host/bootstrap/data/environment/$BUILD_ENV/base-seed.yaml -i /ceph-host/data/templates/cepheus_node_rhel_nonosd.ks.erb.j2 -o /tmp/build/iso/postinstall/ceph-host/cookbooks/cepheus/templates/default/cepheus_node_rhel_nonosd.ks.erb"
  do_on_node $vm "sudo /ceph-host/data/templates/template_engine -d /ceph-host/bootstrap/data/environment/$BUILD_ENV/base-seed.yaml -i /ceph-host/data/templates/cepheus_node_rhel_osd.ks.erb.j2 -o /tmp/build/iso/postinstall/ceph-host/cookbooks/cepheus/templates/default/cepheus_node_rhel_osd.ks.erb"

  do_on_node $vm "cp /ceph-host/bootstrap/data/environment/$BUILD_ENV/rack01-node-seed.yaml /tmp/."
  do_on_node $vm "cp /ceph-host/bootstrap/data/environment/$BUILD_ENV/rack02-node-seed.yaml /tmp/."
  do_on_node $vm "cp /ceph-host/bootstrap/data/environment/$BUILD_ENV/rack03-node-seed.yaml /tmp/."

  do_on_node $vm "cp /tmp/rack01-node-seed.yaml /tmp/rack-node-seed.yaml"
  do_on_node $vm "sed '/---/d' /tmp/rack02-node-seed.yaml >> /tmp/rack-node-seed.yaml"
  do_on_node $vm "sed '/---/d' /tmp/rack03-node-seed.yaml >> /tmp/rack-node-seed.yaml"

  do_on_node $vm "sudo /ceph-host/data/templates/template_engine -d /tmp/rack-node-seed.yaml -i /tmp/build/iso/postinstall/ceph-host/environments/$env.json.j2 -o /tmp/build/iso/postinstall/ceph-host/environments/$env.json"
  do_on_node $vm "sudo rm -f /tmp/build/iso/postinstall/ceph-host/environments/$env.json.j2"

  # Build ISO with custom kickstart
  echo "===> Generating new ISO..."
  echo
  # This commented line is for possible future reference - ls -1 | sed -e 's/\.rpm$//' | grep 'x86_64' | xargs yum install --downloadonly --downloaddir=/tmp/repos
  # mkisofs
  do_on_node $vm "TODAY=\$(date +'%Y-%m-%d'); sudo genisoimage -r -J -N -d -hide-rr-moved -R -T -no-emul-boot -boot-load-size 4 -boot-info-table -V \"$ISOVOLUMEID\" -p \"$PACKAGER\" -A \"$ISOVOLUMEID - \$TODAY\" -b isolinux/isolinux.bin -c isolinux/boot.cat -x \"lost+found\" -eltorito-alt-boot -e images/efiboot.img -no-emul-boot -o /tmp/$CHEF_CEPHEUS_ENV-$COBBLER_BOOTSTRAP_ISO /tmp/build/iso"
  echo "===> Generating MD5 in ISO..."
  echo

  do_on_node $vm "sudo implantisomd5 /tmp/$CHEF_CEPHEUS_ENV-$COBBLER_BOOTSTRAP_ISO"

  echo "===> Copying $CHEF_CEPHEUS_ENV-$COBBLER_BOOTSTRAP_ISO to $BOOTSTRAP_CACHE_DIR/build/iso/out"
  echo
  do_on_node $vm "cp /tmp/$CHEF_CEPHEUS_ENV-$COBBLER_BOOTSTRAP_ISO /ceph-files/build/iso/out/."
fi

cp -p $REPO_ROOT/bootstrap/vms/vagrant/Vagrantfile_cepheus $REPO_ROOT/bootstrap/vms/vagrant/Vagrantfile

echo
echo "------------------------------------------"
echo "Cepheus $vm (BUILD SERVER) created!"
echo "------------------------------------------"
echo
echo "vagrant ssh $vm"
echo
echo "Finished in $SECONDS seconds"
